{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smilewilson1999/XAI/blob/main/Assignment%203%20-%20Interpretable%20ML/Interpretable_ML_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-CJ59b5zjQ2"
      },
      "source": [
        "# AIPI 590 - XAI | Assignment #03\n",
        "### Description\n",
        "### Your Name: Wilson Tseng\n",
        "\n",
        "#### Assignment 3 - Interpretable ML:\n",
        "[GitHub Link](https://github.com/smilewilson1999/XAI/tree/84fd6d65d674d198f80e6197273b1fb01df0fe74/Assignment%203%20-%20Interpretable%20ML)\n",
        "\n",
        "\n",
        "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/smilewilson1999/XAI/blob/main/Assignment%203%20-%20Interpretable%20ML/Customer%20Churn%20Analysis.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YbClLEdzjQ3"
      },
      "source": [
        "## DO:\n",
        "* Use markdown and comments effectively\n",
        "* Pull out classes and functions into scripts\n",
        "* Ensure cells are executed in order and avoid skipping cells to maintain reproducibility\n",
        "* Choose the appropriate runtime (i.e. GPU) if needed\n",
        "* If you are using a dataset that is too large to put in your GitHub repository, you must either pull it in via Hugging Face Datasets or put it in an S3 bucket and use boto3 to pull from there.\n",
        "* Use versioning on all installs (ie pandas==1.3.0) to ensure consistency across versions\n",
        "* Implement error handling where appropriate\n",
        "\n",
        "## DON'T:\n",
        "* Absolutely NO sending us Google Drive links or zip files with data (see above).\n",
        "* Load packages throughout the notebook. Please load all packages in the first code cell in your notebook.\n",
        "* Add API keys or tokens directly to your notebook!!!! EVER!!!\n",
        "* Include cells that you used for testing or debugging. Delete these before submission\n",
        "* Have errors rendered in your notebook. Fix errors prior to submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv8NFvLlzjQ4",
        "outputId": "0b2263d8-4cbe-4d67-f03a-2a1a5e5f1693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'XAI'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 38 (delta 13), reused 29 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (38/38), 22.52 MiB | 14.78 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n",
            "/content/XAI/Assignment 3 - Interpretable ML\n",
            "'Customer Churn Analysis.ipynb'   WA_Fn-UseC_-Telco-Customer-Churn.csv\n",
            "'Duke AI XAI template.ipynb'\n"
          ]
        }
      ],
      "source": [
        "# Please use this to connect your GitHub repository to your Google Colab notebook\n",
        "# Connects to any needed files from GitHub and Google Drive\n",
        "import os\n",
        "\n",
        "# Remove Colab default sample_data\n",
        "!rm -r ./sample_data\n",
        "\n",
        "# Clone GitHub files to colab workspace\n",
        "repo_name = \"XAI\" # Change to your repo name\n",
        "git_path = 'https://github.com/smilewilson1999/XAI.git' #Change to your path\n",
        "!git clone \"{git_path}\"\n",
        "\n",
        "# Install dependencies from requirements.txt file\n",
        "#!pip install -r \"{os.path.join(repo_name,'requirements.txt')}\" #Add if using requirements.txt\n",
        "\n",
        "# Change working directory to location of notebook\n",
        "notebook_dir = 'Assignment 3 - Interpretable ML'\n",
        "path_to_notebook = os.path.join(repo_name, notebook_dir)\n",
        "%cd \"{path_to_notebook}\"\n",
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpxJ8RZezjQ4"
      },
      "source": [
        "#### Using environment variables in Google Colab\n",
        "\n",
        "In Google Colab, locate the key button on the left side of the screen. You can enter in any environment variables or API keys here and they will remain private.\n",
        "\n",
        "Then add the environment variables to your notebook using the code below.\n",
        "\n",
        "Make sure to document in your notebook if you are using API keys and how to get them (ie share a link for documentation to get a Hugging Face API Key if you are using Hugging Face)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_B9l_vRzjQ4"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('secretName')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4878db18"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries and load the dataset\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
        "from pygam import LogisticGAM, s, f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aca4b7d",
        "outputId": "6470958c-f1c9-44f7-f8e3-7e60b8058d6e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customerID</th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>...</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7590-VHVEG</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5575-GNVDE</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3668-QPYBK</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7795-CFOCW</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>45</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>42.30</td>\n",
              "      <td>1840.75</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9237-HQITU</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
              "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
              "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
              "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
              "3  7795-CFOCW    Male              0      No         No      45           No   \n",
              "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
              "\n",
              "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
              "0  No phone service             DSL             No  ...               No   \n",
              "1                No             DSL            Yes  ...              Yes   \n",
              "2                No             DSL            Yes  ...               No   \n",
              "3  No phone service             DSL            Yes  ...              Yes   \n",
              "4                No     Fiber optic             No  ...               No   \n",
              "\n",
              "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
              "0          No          No              No  Month-to-month              Yes   \n",
              "1          No          No              No        One year               No   \n",
              "2          No          No              No  Month-to-month              Yes   \n",
              "3         Yes          No              No        One year               No   \n",
              "4          No          No              No  Month-to-month              Yes   \n",
              "\n",
              "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
              "0           Electronic check          29.85         29.85    No  \n",
              "1               Mailed check          56.95        1889.5    No  \n",
              "2               Mailed check          53.85        108.15   Yes  \n",
              "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
              "4           Electronic check          70.70        151.65   Yes  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('./WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "\n",
        "# Display the first few rows of the dataset to confirm successful loading\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "657f3d96"
      },
      "source": [
        "\n",
        "## 2. Logistic Regression\n",
        "\n",
        "We will use logistic regression to predict churn since the churn variable is binary (0 for staying, 1 for churning). We will interpret the model's coefficients and evaluate its performance using appropriate classification metrics.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a25ebb99"
      },
      "source": [
        "\n",
        "## 1. Exploratory Data Analysis (EDA)\n",
        "\n",
        "We will first perform some exploratory data analysis (EDA) to understand the relationships between different features and the target variable (churn). This will help us determine the assumptions for linear, logistic, and generalized additive models.\n",
        "\n",
        "We will use various visualizations and statistical methods to check for relationships and patterns.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e55e4650",
        "outputId": "453465b3-26c3-456c-9c17-5803bc29c610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7863733144073811\n",
            "AUC: 0.819521359735837\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86      1036\n",
            "           1       0.60      0.56      0.58       373\n",
            "\n",
            "    accuracy                           0.79      1409\n",
            "   macro avg       0.72      0.71      0.72      1409\n",
            "weighted avg       0.78      0.79      0.78      1409\n",
            "\n",
            "Confusion Matrix:\n",
            " [[898 138]\n",
            " [163 210]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Handle missing or non-numeric values in 'TotalCharges' with median imputation\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')  # Convert to numeric, set errors to NaN\n",
        "df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)  # Replace NaN with the median value\n",
        "\n",
        "# Convert 'Churn' column to binary (0 = No, 1 = Yes)\n",
        "df['Churn'] = df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "# Define features and target variable\n",
        "X = df[['tenure', 'MonthlyCharges', 'TotalCharges']]  # Using numerical features for simplicity\n",
        "y = df['Churn']\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the logistic regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg_model = LogisticRegression(max_iter=1000)\n",
        "log_reg_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_log = log_reg_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model using classification metrics\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
        "print(\"AUC:\", roc_auc_score(y_test, log_reg_model.predict_proba(X_test)[:, 1]))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_log))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_log))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f830ab7"
      },
      "source": [
        "\n",
        "## 2. Logistic Regression\n",
        "\n",
        "We will use logistic regression to predict churn since the churn variable is binary (0 for staying, 1 for churning). We will interpret the model's coefficients and evaluate its performance using appropriate classification metrics.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e63e643",
        "outputId": "73b7f831-9c21-4aba-a816-cc01061b3e50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Unique values in 'Churn' column before conversion:\n",
            "[0 1]\n",
            "\n",
            "Value counts in 'Churn' column before conversion:\n",
            "0    5174\n",
            "1    1869\n",
            "Name: Churn, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Unique values in 'Churn' column before conversion\n",
        "print(\"\\nUnique values in 'Churn' column before conversion:\")\n",
        "print(df['Churn'].unique())\n",
        "\n",
        "# Value counts in 'Churn' column before conversion\n",
        "print(\"\\nValue counts in 'Churn' column before conversion:\")\n",
        "print(df['Churn'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e158287e",
        "outputId": "387d2b44-607d-4b79-e087-8ea42f9ede5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values in 'Churn' column before any conversion:\n",
            "[0 1]\n",
            "\n",
            "Original class distribution:\n",
            "0    5174\n",
            "1    1869\n",
            "Name: Churn, dtype: int64\n",
            "\n",
            "Training set class distribution:\n",
            "0    4139\n",
            "1    1495\n",
            "Name: Churn, dtype: int64\n",
            "\n",
            "Test set class distribution:\n",
            "0    1035\n",
            "1     374\n",
            "Name: Churn, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "exception calling callback for <Future at 0x7f9200232340 state=finished raised BrokenProcessPool>\n",
            "joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/wilson/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 426, in _process_worker\n",
            "    call_item = call_queue.get(block=True, timeout=timeout)\n",
            "  File \"/Users/wilson/opt/anaconda3/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "AttributeError: Can't get attribute 'SafeFunction' on <module 'joblib._parallel_backends' from '/Users/wilson/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py'>\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/wilson/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/_base.py\", line 625, in _invoke_callbacks\n",
            "  File \"/Users/wilson/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 359, in __call__\n",
            "    *,\n",
            "  File \"/Users/wilson/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 792, in dispatch_next\n",
            "    def __call__(self, out):\n",
            "  File \"/Users/wilson/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
            "  File \"/Users/wilson/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
            "    # The computation are running and the status is pending.\n",
            "  File \"/Users/wilson/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 531, in apply_async\n",
            "    idle_worker_timeout=300, **memmappingexecutor_args):\n",
            "  File \"/Users/wilson/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/reusable_executor.py\", line 177, in submit\n",
            "    mp.util.debug(\n",
            "  File \"/Users/wilson/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 1102, in submit\n",
            "    self._processes = {}\n",
            "joblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n"
          ]
        },
        {
          "ename": "BrokenProcessPool",
          "evalue": "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/wilson/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 426, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n  File \"/Users/wilson/opt/anaconda3/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n    return _ForkingPickler.loads(res)\nAttributeError: Can't get attribute 'SafeFunction' on <module 'joblib._parallel_backends' from '/Users/wilson/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py'>\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/_y/cr7pfb1j2gz40z068gp0n7r40000gn/T/ipykernel_90642/136763535.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Fit the model to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Best parameters from GridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                         \u001b[0;34m\"Fitting {0} folds for each of {1} candidates,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m                         \" totalling {2} fits\".format(\n\u001b[0;32m--> 841\u001b[0;31m                             \u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_candidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_candidates\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m                         )\n\u001b[1;32m    843\u001b[0m                     )\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0mbest_index_\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mcandidate\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0msetting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mdict\u001b[0m \u001b[0mat\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_index_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mgives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m         \"\"\"\n\u001b[1;32m    794\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m         \u001b[0mrefit_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"score\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0mpointed\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mJOBLIB_TEMP_FOLDER\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m               \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mshm\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0mexists\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mwritable\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m               \u001b[0mRAM\u001b[0m \u001b[0mdisk\u001b[0m \u001b[0mfilesystem\u001b[0m \u001b[0mavailable\u001b[0m \u001b[0mby\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mon\u001b[0m \u001b[0mmodern\u001b[0m \u001b[0mLinux\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[0mWarning\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mexperimental\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msubject\u001b[0m \u001b[0mto\u001b[0m \u001b[0mchange\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[0mversion\u001b[0m \u001b[0mof\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     \"\"\"\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_worker_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             context_id=parallel._id, **memmappingexecutor_args)\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/_base.py\u001b[0m in \u001b[0;36m_invoke_callbacks\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_parallel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"backend\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_parallel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_jobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_parallel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"verbose\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0;31m#                     METHODS CALLED BY CALLBACK THREADS                 #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m     \u001b[0;31m##########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m         \u001b[0;34m\"\"\"Function called by the callback thread after a job is completed.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0moutcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTASK_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mTASK_ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0;31m# The computation are running and the status is pending.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m         \u001b[0;31m# Check that we did not wait for this jobs more than `timeout`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     def configure(self, n_jobs=1, parallel=None, prefer=None, require=None,\n\u001b[0;32m--> 531\u001b[0;31m                   idle_worker_timeout=300, **memmappingexecutor_args):\n\u001b[0m\u001b[1;32m    532\u001b[0m         \u001b[0;34m\"\"\"Build a process executor and return the number of workers\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/reusable_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexecutor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mis_reused\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 mp.util.debug(\n\u001b[0m\u001b[1;32m    178\u001b[0m                     \u001b[0;34mf\"Create a executor with max_workers={max_workers}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 )\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;31m# Map of pids to processes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_processes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;31m# Internal variables of the ProcessPoolExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenProcessPool\u001b[0m: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable."
          ]
        }
      ],
      "source": [
        "# Handle missing or non-numeric values in 'TotalCharges' with median imputation\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')  # Convert to numeric, set errors to NaN\n",
        "df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)  # Replace NaN with the median value\n",
        "\n",
        "# Verify that 'Churn' column contains the correct values\n",
        "print(\"Unique values in 'Churn' column before any conversion:\")\n",
        "print(df['Churn'].unique())\n",
        "\n",
        "# Define features and target variable\n",
        "numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "categorical_features = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
        "                        'PhoneService', 'MultipleLines', 'InternetService',\n",
        "                        'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
        "                        'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
        "                        'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "df_encoded[numerical_features] = scaler.fit_transform(df_encoded[numerical_features])\n",
        "\n",
        "# Prepare features and target variable\n",
        "X = df_encoded.drop(['customerID', 'Churn'], axis=1)\n",
        "y = df_encoded['Churn']\n",
        "\n",
        "# Check the distribution of the target variable\n",
        "print(\"\\nOriginal class distribution:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "# Split the data into training and test sets using stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Check the distribution in the training set\n",
        "print(\"\\nTraining set class distribution:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "# Check the distribution in the test set\n",
        "print(\"\\nTest set class distribution:\")\n",
        "print(y_test.value_counts())\n",
        "\n",
        "# Initialize the logistic regression model with class_weight='balanced'\n",
        "log_reg = LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear')\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the model to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters from GridSearchCV\n",
        "print(\"\\nBest parameters found:\", grid_search.best_params_)\n",
        "\n",
        "# Use the best estimator from GridSearchCV\n",
        "best_log_reg_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_log = best_log_reg_model.predict(X_test)\n",
        "y_pred_proba = best_log_reg_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate the model using classification metrics\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred_log))\n",
        "print(\"AUC:\", roc_auc_score(y_test, y_pred_proba))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_log))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_log))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "293faf0a"
      },
      "source": [
        "\n",
        "## 3. Logistic Regression\n",
        "\n",
        "Next, we will treat churn as a binary variable and build a logistic regression model to predict the probability of churn. We will interpret the coefficients and use appropriate metrics to evaluate the model's performance.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ea0e5ac",
        "outputId": "4feb8a17-8b40-4a33-8bdb-0e21f6075163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression AUC: 0.8419979849647369\n",
            "Logistic Regression Accuracy: 0.8055358410220014\n",
            "Logistic Regression Coefficients: \n",
            "                                        Coefficient\n",
            "tenure                                   -1.239793\n",
            "MonthlyCharges                           -0.495779\n",
            "TotalCharges                              0.509188\n",
            "gender_Male                               0.021771\n",
            "SeniorCitizen_1                           0.146006\n",
            "Partner_Yes                               0.020953\n",
            "Dependents_Yes                           -0.226059\n",
            "PhoneService_Yes                         -0.113063\n",
            "MultipleLines_No phone service            0.115419\n",
            "MultipleLines_Yes                         0.367838\n",
            "InternetService_Fiber optic               1.207241\n",
            "InternetService_No                       -0.176330\n",
            "OnlineSecurity_No internet service       -0.176330\n",
            "OnlineSecurity_Yes                       -0.343530\n",
            "OnlineBackup_No internet service         -0.176330\n",
            "OnlineBackup_Yes                         -0.093716\n",
            "DeviceProtection_No internet service     -0.176330\n",
            "DeviceProtection_Yes                      0.040339\n",
            "TechSupport_No internet service          -0.176330\n",
            "TechSupport_Yes                          -0.293719\n",
            "StreamingTV_No internet service          -0.176330\n",
            "StreamingTV_Yes                           0.385904\n",
            "StreamingMovies_No internet service      -0.176330\n",
            "StreamingMovies_Yes                       0.386476\n",
            "Contract_One year                        -0.687107\n",
            "Contract_Two year                        -1.329410\n",
            "PaperlessBilling_Yes                      0.372227\n",
            "PaymentMethod_Credit card (automatic)    -0.033484\n",
            "PaymentMethod_Electronic check            0.383425\n",
            "PaymentMethod_Mailed check                0.072370\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "# Build the logistic regression model\n",
        "log_reg_model = LogisticRegression(max_iter=1000)\n",
        "log_reg_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities on test set\n",
        "y_pred_proba = log_reg_model.predict_proba(X_test)[:, 1]\n",
        "y_pred_log = log_reg_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "accuracy = accuracy_score(y_test, y_pred_log)\n",
        "\n",
        "print(\"Logistic Regression AUC:\", roc_auc)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy)\n",
        "\n",
        "# Coefficients interpretation\n",
        "log_coefficients = pd.DataFrame(log_reg_model.coef_[0], X.columns, columns=['Coefficient'])\n",
        "print(\"Logistic Regression Coefficients: \\n\", log_coefficients)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4f45cef"
      },
      "source": [
        "\n",
        "## 4. Generalized Additive Model (GAM)\n",
        "\n",
        "Finally, we will build a generalized additive model (GAM) to model the non-linear relationships between customer features and churn. We will interpret the model and assess its performance.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b111a4f0",
        "outputId": "37d81446-ed32-4a68-fc97-8c99ab8a19b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type of 'Churn' column: int64\n",
            "Unique values in 'Churn' column:\n",
            "[0]\n",
            "Non-numerical columns: Index([], dtype='object')\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/_y/cr7pfb1j2gz40z068gp0n7r40000gn/T/ipykernel_90642/4136931064.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mX_class0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_class0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m )\n\u001b[0;32m---> 41\u001b[0;31m X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mX_class1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_class1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m )\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2173\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2174\u001b[0m             \u001b[0;31m# if there are ties in the class-counts, we want\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2175\u001b[0;31m             \u001b[0;31m# to make sure to break them anew in each iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2176\u001b[0m             \u001b[0mn_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_approximate_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2177\u001b[0m             \u001b[0mclass_counts_remaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_counts\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1855\u001b[0m       \u001b[0mTest\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m     \u001b[0mFold\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1857\u001b[0;31m       \u001b[0mTrain\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1858\u001b[0m       \u001b[0mTest\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m     \u001b[0mFold\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ],
      "source": [
        "# Handle missing or non-numeric values in 'TotalCharges'\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)\n",
        "\n",
        "# Verify the 'Churn' column\n",
        "print(\"Data type of 'Churn' column:\", df['Churn'].dtype)\n",
        "print(\"Unique values in 'Churn' column:\")\n",
        "print(df['Churn'].unique())\n",
        "\n",
        "# Identify all categorical features\n",
        "categorical_features = [\n",
        "    'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
        "    'PhoneService', 'MultipleLines', 'InternetService',\n",
        "    'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
        "    'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
        "    'Contract', 'PaperlessBilling', 'PaymentMethod'\n",
        "]\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# Prepare features and target variable\n",
        "X = df_encoded.drop(['customerID', 'Churn'], axis=1)\n",
        "y = df_encoded['Churn']\n",
        "\n",
        "# Verify that all features are numerical\n",
        "non_numerical = X.select_dtypes(include=['object']).columns\n",
        "print(\"Non-numerical columns:\", non_numerical)\n",
        "\n",
        "# Separate the classes\n",
        "X_class0 = X[y == 0]\n",
        "X_class1 = X[y == 1]\n",
        "y_class0 = y[y == 0]\n",
        "y_class1 = y[y == 1]\n",
        "\n",
        "# Split each class separately\n",
        "X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(\n",
        "    X_class0, y_class0, test_size=0.2, random_state=42\n",
        ")\n",
        "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(\n",
        "    X_class1, y_class1, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Combine the splits\n",
        "X_train = pd.concat([X_train_0, X_train_1], axis=0).reset_index(drop=True)\n",
        "X_test = pd.concat([X_test_0, X_test_1], axis=0).reset_index(drop=True)\n",
        "y_train = pd.concat([y_train_0, y_train_1], axis=0).reset_index(drop=True)\n",
        "y_test = pd.concat([y_test_0, y_test_1], axis=0).reset_index(drop=True)\n",
        "\n",
        "# Shuffle the training and test sets\n",
        "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
        "X_test, y_test = shuffle(X_test, y_test, random_state=42)\n",
        "\n",
        "# Verify class distribution in y_test\n",
        "print(\"\\nClass distribution in y_test:\")\n",
        "print(y_test.value_counts())\n",
        "\n",
        "# Build the GAM model\n",
        "\n",
        "# For computational efficiency, use splines on selected features\n",
        "# Let's assume the first 10 features are most important\n",
        "terms = s(0)\n",
        "for i in range(1, min(10, X_train.shape[1])):\n",
        "    terms += s(i)\n",
        "\n",
        "# Add linear terms for the rest\n",
        "if X_train.shape[1] > 10:\n",
        "    for i in range(10, X_train.shape[1]):\n",
        "        terms += l(i)\n",
        "\n",
        "# Train the model\n",
        "gam = LogisticGAM(terms).gridsearch(X_train.values, y_train.values)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_prob = gam.predict_proba(X_test.values)\n",
        "y_pred = gam.predict(X_test.values)\n",
        "\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"AUC:\", roc_auc_score(y_test, y_pred_prob))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b486641e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}